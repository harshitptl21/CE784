{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f36c1a31",
   "metadata": {},
   "source": [
    "# Traffic Prediction (Demand Prediction)\n",
    "## Import packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3fcbbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def compute_metric(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_true[np.where(y_true > 5)[0]], y_pred[np.where(y_true > 5)[0]])\n",
    "    return mae, rmse, mape\n",
    "  \n",
    "def get_dataloader(X, y, device, bs, shuffle):\n",
    "    return torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.FloatTensor(X).to(device), \n",
    "                    torch.FloatTensor(y).to(device)), batch_size=bs, shuffle=shuffle, drop_last=False)\n",
    "\n",
    "def calculate_metric_torch(true, pred, mask_value=5):\n",
    "    mae = torch.mean(torch.abs(true - pred))\n",
    "    rmse = torch.sqrt(torch.mean((pred - true) ** 2))\n",
    "    if mask_value != None:\n",
    "        mask = torch.gt(true, mask_value)\n",
    "        pred = torch.masked_select(pred, mask)\n",
    "        true = torch.masked_select(true, mask)\n",
    "    mape = torch.mean(torch.abs(torch.div((true - pred), true)))\n",
    "    return mae, rmse, mape\n",
    "\n",
    "def trainer(model, lr, epochs, train_loader, val_loader, test_loader):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    MSE = nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = list()\n",
    "        for src, trg in train_loader:\n",
    "            pred = model(src)\n",
    "            loss = MSE(pred, trg)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            epoch_loss.append(loss.item())\n",
    "        epoch_loss = np.mean(epoch_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        best_rmse = epoch_loss\n",
    "        with torch.no_grad():\n",
    "            preds, trues = list(), list()\n",
    "            for src, trg in val_loader:\n",
    "                pred = model(src)\n",
    "                preds.append(pred)\n",
    "                trues.append(trg)\n",
    "            mae, rmse, mape = calculate_metric_torch(torch.cat(trues), torch.cat(preds))\n",
    "\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                preds, trues = list(), list()\n",
    "                for src, trg in test_loader:\n",
    "                    pred = model(src)\n",
    "                    preds.append(pred)\n",
    "                    trues.append(trg)\n",
    "                test_mae, test_rmse, test_mape = calculate_metric_torch(torch.cat(trues), torch.cat(preds))\n",
    "        \n",
    "        print('Epoch %d, training loss: %.3f, validation mae: %.3f, rmse: %.3f, mape: %.3f' % (epoch, epoch_loss, mae, rmse, mape))\n",
    "    \n",
    "    return test_mae, test_rmse, test_mape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d39cd5f",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e71a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = np.load('./processed_demand_datasetsMAN.npz')\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = datasets['trainX'], datasets['valX'], datasets['testX'], datasets['trainy'], datasets['valy'], datasets['testy']\n",
    "\n",
    "\n",
    "num_nodes = X_train.shape[0]\n",
    "edges = np.load('./edges_GAman.npy')\n",
    "\n",
    "adj = np.zeros((num_nodes, num_nodes))\n",
    "\n",
    "for i in range(num_nodes): \n",
    "    adj[i,i] = 1\n",
    "    \n",
    "for i in range(len(edges)):\n",
    "    adj[edges[i,0], edges[i,1]] = 1\n",
    "    \n",
    "adj = torch.LongTensor(adj)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c5dc979",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afb05e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mae: 2.164, rmse: 4.394, mape: 21.693\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(random_state=1000)\n",
    "rf.fit(X_train.reshape(-1,42), y_train.reshape(-1))\n",
    "\n",
    "pred = rf.predict(X_test.reshape(-1,42))\n",
    "mae, rmse, mape = compute_metric(y_test.reshape(-1), pred)\n",
    "errors_rf = pd.DataFrame({'MAE': mae, 'RMSE': rmse, 'MAPE': mape}, index=['RF'])\n",
    "\n",
    "print('test mae: %.3f, rmse: %.3f, mape: %.3f' % (mae, rmse, mape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1427b2a7",
   "metadata": {},
   "source": [
    "## GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19ccb09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mae: 2.224, rmse: 4.432, mape: 22.182\n"
     ]
    }
   ],
   "source": [
    "gbdt = GradientBoostingRegressor(random_state=1000)\n",
    "gbdt.fit(X_train.reshape(-1,42), y_train.reshape(-1))\n",
    "\n",
    "pred = gbdt.predict(X_test.reshape(-1,42))\n",
    "mae, rmse, mape = compute_metric(y_test.reshape(-1), pred)\n",
    "errors_gbdt = pd.DataFrame({'MAE': mae, 'RMSE': rmse, 'MAPE': mape}, index=['GBDT'])\n",
    "\n",
    "print('test mae: %.3f, rmse: %.3f, mape: %.3f' % (mae, rmse, mape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7bef049d",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61100aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mae: 2.273, rmse: 4.587, mape: 23.100\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor(random_state=200, max_iter=400)\n",
    "mlp.fit(X_train.reshape(-1,42), y_train.reshape(-1))\n",
    "\n",
    "pred = mlp.predict(X_test.reshape(-1,42))\n",
    "mae, rmse, mape = compute_metric(y_test.reshape(-1), pred)\n",
    "errors_mlp = pd.DataFrame({'MAE': mae, 'RMSE': rmse, 'MAPE': mape}, index=['MLP'])\n",
    "\n",
    "print('test mae: %.3f, rmse: %.3f, mape: %.3f' % (mae, rmse, mape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58252853",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74edb7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, hidden_dim1, num_layers, hidden_dim2):\n",
    "        super().__init__()\n",
    "        self.GRU = nn.GRU(1, hidden_dim1, num_layers, batch_first=True)\n",
    "        self.Dense = nn.Sequential(nn.Linear(hidden_dim1, hidden_dim2), nn.ReLU(), nn.Linear(hidden_dim2, 1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        o, h = self.GRU(x)\n",
    "        x = self.Dense(h[-1])\n",
    "        return x.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fe72db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss: 136.957, validation mae: 3.005, rmse: 6.478, mape: 0.303\n",
      "Epoch 1, training loss: 26.717, validation mae: 2.838, rmse: 6.337, mape: 0.284\n",
      "Epoch 2, training loss: 25.051, validation mae: 3.144, rmse: 6.422, mape: 0.315\n",
      "test mae: 2.526, rmse: 4.655, mape: 0.252\n"
     ]
    }
   ],
   "source": [
    "train_loader = get_dataloader(X_train.reshape(-1,42,1), y_train.reshape(-1), device, 64, True)\n",
    "val_loader = get_dataloader(X_val.reshape(-1,42,1), y_val.reshape(-1), device, y_test.reshape(-1).shape[0], True)\n",
    "test_loader = get_dataloader(X_test.reshape(-1,42,1), y_test.reshape(-1), device, y_test.reshape(-1).shape[0], False)\n",
    "\n",
    "#####################################################################################################################\n",
    "# After class, you can try different learning rates and training epochs yourself. \n",
    "# Here for quick results, we just set the training epoch to 3.\n",
    "lr = 0.001\n",
    "epochs = 3\n",
    "# For the sake of simplicity, we also omitted the parameter tuning process here. \n",
    "# The correct way is to adjust on the validation set to get the best hyperparameters, and then evaluate the model based on the test set.\n",
    "#####################################################################################################################\n",
    "\n",
    "model = GRU(64, 2, 32).to(device)\n",
    "\n",
    "mae, rmse, mape = trainer(model, lr, epochs, train_loader, val_loader, test_loader)\n",
    "errors_gru = pd.DataFrame({'MAE': mae.item(), 'RMSE': rmse.item(), 'MAPE': mape.item()}, index=['GRU'])\n",
    "\n",
    "print('test mae: %.3f, rmse: %.3f, mape: %.3f' % (mae.item(), rmse.item(), mape.item()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2aa1e5c7",
   "metadata": {},
   "source": [
    "## GRU-GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, device, in_dim, out_dim, alpha=0.2, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.alpha = alpha\n",
    "        self.dropout = dropout\n",
    "        self.weights = nn.Parameter(torch.FloatTensor(in_dim, out_dim))\n",
    "        nn.init.xavier_normal_(self.weights.data, gain=1.414)\n",
    "        self.a = nn.Parameter(torch.FloatTensor(2*out_dim, 1))\n",
    "        nn.init.xavier_normal_(self.a.data, gain=1.414)\n",
    "\n",
    "    def forward(self, h, adj):\n",
    "        \"\"\"\n",
    "        h: (bs, num_node, in_dim)\n",
    "        adj: (num_node, num_node)\n",
    "        return (bs, num_node, out_dim)\n",
    "        \"\"\"\n",
    "        bs, num_node, in_dim = h.size()\n",
    "        src, trg = torch.nonzero(adj.long(), as_tuple=True)\n",
    "        \n",
    "        Wh = torch.matmul(h, self.weights) # (bs, num_node, out_dim)\n",
    "        edge_h = torch.cat([Wh[:,src,:], Wh[:,trg,:]], dim=-1) # (bs, num_edges, 2*out_dim)\n",
    "        edge_e = F.leaky_relu(torch.matmul(edge_h, self.a), negative_slope=self.alpha).squeeze(-1) # (bs, num_edges)\n",
    "\n",
    "        attention = -9e15*torch.ones(bs, num_node, num_node).to(self.device) #（bs, num_node, num_node)\n",
    "        attention[:, src, trg] = edge_e\n",
    "        attention = F.dropout(F.softmax(attention, dim=-1), self.dropout) #（bs, num_node, num_node)\n",
    "\n",
    "        h_prime = torch.einsum('bij,bjo->bio', attention, Wh)\n",
    "\n",
    "        return h_prime\n",
    "    \n",
    "    \n",
    "class GRUGAT(nn.Module):\n",
    "    def __init__(self, device, in_dim, out_dim, num_node, adj):\n",
    "        super().__init__()\n",
    "        self.adj = adj\n",
    "        self.gru = nn.GRU(1, in_dim, 2, batch_first=True)\n",
    "        self.gat = GATLayer(device, in_dim, out_dim)\n",
    "        self.end_conv = nn.Conv1d(out_dim, 1, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (bs, num_node, time_step)\n",
    "        X = []\n",
    "        for i in range(x.size(1)):\n",
    "            o, h = self.gru(x[:,i,:].unsqueeze(-1))\n",
    "            X.append(h[-1])\n",
    "        X = torch.stack(X)\n",
    "        X = self.gat(X.permute(1,0,2), self.adj) # (bs, num_node, 16)\n",
    "        X = self.end_conv(X.permute(0,2,1))\n",
    "        return X.squeeze(1)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a769b89d",
   "metadata": {},
   "source": [
    "For a complex model, such as the hybrid model of GAT and GRU used here, the training time is longer due to the larger number of parameters involved. The hyperparameter tuning process of complex models is usually more complicated, and some training tricks need to be involved, such as learning rate decay and early stopping mechanism. \\\n",
    "Here, also for simplicity and quick display of results, we only set the training epoch to 3 and set the learning rate to a constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f415df23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss: 688.228, validation mae: 14.236, rmse: 22.770, mape: 0.618\n",
      "Epoch 1, training loss: 612.897, validation mae: 12.425, rmse: 19.892, mape: 0.761\n",
      "Epoch 2, training loss: 479.127, validation mae: 10.646, rmse: 19.284, mape: 0.652\n",
      "test mae: 10.500, rmse: 19.010, mape: 0.645\n"
     ]
    }
   ],
   "source": [
    "train_loader = get_dataloader(X_train.transpose(1,0,2), y_train.T, device, 36, True)\n",
    "val_loader = get_dataloader(X_val.transpose(1,0,2), y_val.T, device, 72, False)\n",
    "test_loader = get_dataloader(X_test.transpose(1,0,2), y_test.T, device, 72, False)\n",
    "\n",
    "lr = 0.01\n",
    "epochs = 3\n",
    "\n",
    "model = GRUGAT(device, 10, 128, 198, adj).to(device)\n",
    "\n",
    "mae, rmse, mape = trainer(model, lr, epochs, train_loader, val_loader, test_loader)\n",
    "errors_grugat = pd.DataFrame({'MAE': mae.item(), 'RMSE': rmse.item(), 'MAPE': mape.item()}, index=['GRU-GAT'])\n",
    "print('test mae: %.3f, rmse: %.3f, mape: %.3f' % (mae.item(), rmse.item(), mape.item()))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee76fcea",
   "metadata": {},
   "source": [
    "## Error comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2512d956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>2.163976</td>\n",
       "      <td>4.393530</td>\n",
       "      <td>21.693186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBDT</th>\n",
       "      <td>2.223783</td>\n",
       "      <td>4.431532</td>\n",
       "      <td>22.182326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>2.273329</td>\n",
       "      <td>4.587292</td>\n",
       "      <td>23.100089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU</th>\n",
       "      <td>2.525941</td>\n",
       "      <td>4.655260</td>\n",
       "      <td>0.252132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU-GAT</th>\n",
       "      <td>10.500470</td>\n",
       "      <td>19.010136</td>\n",
       "      <td>0.645191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MAE       RMSE       MAPE\n",
       "RF        2.163976   4.393530  21.693186\n",
       "GBDT      2.223783   4.431532  22.182326\n",
       "MLP       2.273329   4.587292  23.100089\n",
       "GRU       2.525941   4.655260   0.252132\n",
       "GRU-GAT  10.500470  19.010136   0.645191"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = pd.concat([errors_rf, errors_gbdt, errors_mlp, errors_gru, errors_grugat])\n",
    "errors\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c26998198c150a5d49337a78fda498219c22346a083e2a499426c24ff75f162e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
